---
title: "L'IA non pensa?"
tags:
 - "Intelligenza-Artificiale"
source: Facebook 
date: 2025-08-11
---

Nota: Ogni volta che qualcuno dice con troppa sicurezza che una AI "non pensa/pensa", "è solo statistica/stiamo arrivando all'AGI", "non capisce/capisce", sta probabilmente facendo un piantino antropocentrico nel primo caso e pubblicità alle big tech nel secondo.

Svolgimento: Ogni volta che una nuova tecnologia si avvicina anche solo di striscio a ciò che chiamiamo “pensiero”, scoppia una rissa intellettuale. È accaduto con i computer scacchisti: negli anni ’60 Hubert Dreyfus bollava i programmi come calcolatori privi di comprensione e nel 1997 la vittoria di Deep Blue su Kasparov rilanciò l’idea che la macchina potesse batterci nel calcolo senza però “capire” il gioco. Con le AI generative la storia si ripete: da una parte abbiamo i pappagallisti – soprannome nato dal celebre paper “On the Dangers of Stochastic Parrots” di Bender & col. – che considerano i modelli linguistici meri replicatori di sequenze plausibili senza alcuna comprensione; dall’altra gli antipappagallisti, che giurano di intravedere nella macchina capacità cognitive, se non addirittura una coscienza. Di fronte a tanto fervore mi sorprende la disinvoltura con cui entrambe le fazioni brandiscono il verbo “pensare”, quasi esistesse un criterio pacifico per stabilire quando qualunque entità lo faccia. Ma un tale criterio (se esiste) è tutto fuorché condiviso e la nostra sicumera rischia di rivelare più i nostri desideri che la realtà.

Se adottiamo una cornice puramente funzionale la partita è breve: pensare significa produrre risposte utili, pertinenti e se possibile creative. Su questo terreno i grandi modelli linguistici vincono facile, perché sfornano sonetti, debuggano software, riassumono ricerche, improvvisano canzoni e dibattono sull’intelligenza artificiale meglio di molti umani. Bollarli come imitatori privi di comprensione, se quel che conta è solo il risultato, non ha alcun senso. Qui non ci interessa come ci arriva, ma che ci arrivi.

Si potrebbe invece parlare di qualia, l’esperienza interiore di che effetto fa sentire dolore, vedere il rosso o ricordare il primo amore. I LLM non hanno esperienze, dunque non pensano. Questa obiezione però si inceppa su un dettaglio: un test per i qualia non esiste neppure per noi, che possiamo essere sicuri solo dei nostri e li ipotizziamo negli altri per analogie fisiche e comportamentali. L’esperienza fenomenologica del mondo è un requisito che posso affermare con certezza soltanto di me stesso, perché per quel che ne so potreste essere gli “zombie filosofici” ipotizzati da Chalmers: identici a me in tutto e per tutto, ma senza esperienze coscienti. In un versante opposto potremmo invece immaginare, con i panpsichisti, che una qualche forma di esperienza elementare accompagni tutta la materia, dalle sinapsi ai transistor.

Terza idea allora: per pensare servono sensi che mi mettano in contatto diretto col mondo. La conoscenza, come la coscienza, è incarnata, la mente non funziona in modo separato dal corpo, ma è strettamente legata all’esperienza fisica e sensoriale dell’individuo. Qui dovremmo attendere che le reti si dotino di telecamere, microfoni e braccia robotiche, cosa che in realtà sta già accadendo. Se seguiamo questa idea la risposta è facile, le AI non capiscono quel che dicono – per ora.

Resta poi l’intenzionalità, il volere qualcosa. E qui, più da buddista che da tecno-apocalittico, mi auguro che non tormenteremo anche le macchine con la piaga del desiderio. Lasciamole fuori dal Samsara! Se non è troppo tardi, almeno: quando un modello si sforza di soddisfare le nostre richieste, non esercita già un desiderio, sia pure eterodiretto? Potremmo considerare accontentare le nostre richieste il drive delle AI?

Ricordiamo comunque che ogni volta che una macchina alza l’asticella spostiamo i paletti delle nostre definizioni per salvare la superiorità umana; prima non bastava il calcolo, poi serviva la creatività, ora il corpo, domani chissà. Il pensiero è un club riservato agli umani, anche se è sufficiente guardarsi attorno con meno snobismo per accorgersi che il mondo vivente è pieno di pensiero non umano. E che il nostro pensiero fa parte di una mente diffusa (Clark & Chalmers) che ora include anche le AI (Chiriatti et al).

Se con il “pensiero” invece vogliamo preservare un primato umano, dovremmo ricordarci che in questa gara ontologica siamo nella scorretta posizione di giudici e giocatori. Anche come categoria per indagare come funzionano le Ai, comunque, il “pensiero” potrebbe testimoniare un approccio residuale, testimone più che altro dell’ambigua altalena tra il desiderio di riprodurre noi stessi e quello di non essere superati dai nostri figli.

Francesco d'Isa su *Facebook*.
